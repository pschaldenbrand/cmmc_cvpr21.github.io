# Contributed Artworks

---

<div id="agosin">
 <a href="http://www.estebanagosin.cl/eng/the_ear.html">![image](https://user-images.githubusercontent.com/1598545/122474335-ebdb2e80-cf77-11eb-9a64-44bb5ea082bb.png)</a>

[__The Ear__](http://www.estebanagosin.cl/eng/the_ear.html) by [Esteban Y Agosin](http://www.estebanagosin.cl/eng/)

The ear is a listening, surveillance, and Artificial Intelligence project. It is a device that collects human voices, 
transcribe them into text, and with that information create new texts. The ear is a machine that through an Artificial
Intelligence system creates ideas in real time based on what it is listening to. This piece could be defined as an 
ironic idea of the surveillance system. In a way, it is not a perfect and functional machine, it constantly makes 
mistakes, degrading the original information from the source, creating erroneous and potentially false information,
digital garbage that in a way undermines the expected fantasies of technology and surveillance systems. The experience
with the piece show how the human voice is transformed into a digital object and that could be analyzed, recorded, 
transformed, stored, and used, questioning the concept, sense and value of the information, privacy and freedom in
our contemporary society, also questioning the relevance of the information collected in surveillance systems, and
the ethical and political limits in this type of devices.
</div>
---

<div  id="chung">
<a href="https://ncchung.com/zenmachine-gallery">![image](https://user-images.githubusercontent.com/1598545/122476695-7bcea780-cf7b-11eb-8b58-a75420079d03.png)</a>

[__Zen Machine__](https://ncchung.com/zenmachine-gallery) by [Neo Christopher Chung](https://cbml.science/)

Zen Machine is a meditative audio-visual installation that answers questions from the audience with a generative hypotic soundscape. Trained on a large corpus of the Sutras, Shastras, Zen teachings, scholarly essays and texts, koans, and tweets, this artificial intelligence algorithm (GPT-2) explores existential and spiritual realms. As koans (paradoxical dialogs used as a meditative device) may be only understood by willing students and perceived as subtle invocation for awakening, our perception of Zen Machine’s answers – and broad AI – depends on our state of mind. To that end, Zen Machine provides an immersive environment and a poetic context. If so, would it be possible for AI to aid in our pursuit of enlightenment?

A series of digital paintings such as "Illusion of falling asleep" (2021), "Unreality of reason" (2021), and "The awe of his supernatural deficiencies" (2021) are created from its interactive exhibition at Galeria Entropia in Wrocław, Poland (9–30/03/2021). The audience questions (as shown in quotes) and answers were fed to a generative AI system to create digital paintings. In particular, Deep Daze combining CLIP (Radford et al. 2019) and Siren (Sitzmann et al. 2020) imagines and visualizes unique scenes based on this new kind of koans. The interplay between texts and paintings provides an opportunity to pause and reflect on potentiality of going beyond anthropocentric understanding.
 
</div>

---

<div id="fernando">
 <a href="https://www.chrisantha.co.uk/post/jungle-in-the-tiger">![image](https://user-images.githubusercontent.com/1598545/122477192-33fc5000-cf7c-11eb-97a5-ffefbbd3b7bd.png)</a>

[__Jungle in the Tiger__](https://www.chrisantha.co.uk/post/jungle-in-the-tiger) by [Chrisantha Fernando](https://www.chrisantha.co.uk/)

A neural L-system was evolved to produce images that satisfy the text description ""Jungle in the Tiger"" according to
a Duel Encoder trained on the ALIGN dataset. 

See the paper [Generative Art Using Neural Visual Grammars and Dual Encoders](https://arxiv.org/abs/2105.00162)
</div>

---

<div id="ojha">
<a href="https://utkarshojha.github.io/inter-domain-gan/">![image](https://user-images.githubusercontent.com/1598545/122570708-da8a3480-d000-11eb-9d66-3e414b61b528.png)
</a>

[__Generating Furry Cars: Disentangling Object Shape and Appearance across Multiple Domains__](https://utkarshojha.github.io/inter-domain-gan/) by [Utkarsh Ojha](https://utkarshojha.github.io/)

We developed a model which can generate images in such a way that different properties of the images (e.g. foreground
shape, background) can be changed independently. Because of this ability, we can mix properties from different domains
to create hybrid images which didn't exist in any domain exclusively; e.g. shape or a car with dog's furry texture to
create a furry car.
</div>

---

<a href="https://youtu.be/05pIId167B8" id="marshall">![image](https://user-images.githubusercontent.com/1598545/122476223-acfaa800-cf7a-11eb-99f7-493312473dbf.png)</a>

[__In The Bleak Midwinter__](https://youtu.be/05pIId167B8) by [Glenn Marshall](https://www.youtube.com/c/GlennMarshallNeuralArt)

An AI generated imagery using text interpreted into pictures featuring the AI synthesised voice of Christopher Lee.

[__Beeple Generator + Image Synthesis__](https://youtu.be/Aest8DgRkMs) by [Glenn Marshall](https://www.youtube.com/c/GlennMarshallNeuralArt)

"Michelangelo once stared at a block of stone for months - before he even BEGAN. 3 Years later, he completed David. Today we can just click buttons and instantly create 'art'. Beeple Generator - click for an instant garish creation of one the world's highest valued living artists. Text to Image Synthesis - type some words to have the AI turn this into a 'masterpiece'. Beeple + AI = Art or Crap?"

---

<a href="https://www.tivonrice.com/models.html" id="rice">
![image](https://user-images.githubusercontent.com/1598545/122474371-f72e5a00-cf77-11eb-9a2e-5a634ef76cc5.png)</a>

[__Models for Environmental Literacy__](https://www.tivonrice.com/models.html) by [Tivon Rice](https://www.tivonrice.com)

Models for Environmental Literacy creatively and critically explores the challenges of describing a landscape, an 
ecosystem, or the specter of environmental collapse through human language. The project further explores how language
and vision are impacted by the mediating agency of new technologies. How do we see, feel, imagine, and talk about the
environment in this post-digital era, when there are indeed non-human/machine agents similarly trained to perceive
“natural” spaces? This project explores these questions, as well as emerging relationships with drone/computer vision
and A.I.

---
<a href="https://youtu.be/bazCs9Kyyt4" id="ross">
![image](https://user-images.githubusercontent.com/1598545/122573144-51c0c800-d003-11eb-98c7-f40f46f5da9b.png)</a>

[__Permanent Visibility__](https://youtu.be/bazCs9Kyyt4) by [Nica Ross](https://nicaross.com/)

A virtual reality based essay that celebrates the failure of surveillance and nonhuman vision when applied to the human
form. The work is the result of capturing gender non-conforming bodies practicing Brazilian Jiu Jitsu in Carnegie 
Mellon's Panoptic Dome - a sensor-free motion capture studio. As the name implies the technology's intention is to 
fully capture and render the "truth" of a body's performance. Throughout the piece Jeremy Bentham's musings on the
perfection of the Panopticon's form are juxtaposed against the Dome's raw data. We see the noisy shadows of bodies
moving across the Dome's walls, digital skeletons popping in and out of sight as their movements shift outside of a
machine's understanding and we are left with the impression of their contact recorded in millions of point clouds. 
Bentham's words describe an omnipotent yet focused power harnessed by surveillance while queer bodies jump in and 
out of understanding in pursuit of joy rather than legibility.

---

<a href="https://tunesfromtheaifrontiers.wordpress.com/2021/06/01/week-36-evigt-forlorad-forever-lost-folk-rnn-v2-sturm/" id="sturm">
![image](https://user-images.githubusercontent.com/1598545/122475928-3a89c800-cf7a-11eb-9d27-bd0a646b266b.png)</a>

[__Tunes from the Ai Frontiers: Week 36: Evigt Förlorad – Forever Lost (folk-rnn v2 + Sturm)__](https://tunesfromtheaifrontiers.wordpress.com/2021/06/01/week-36-evigt-forlorad-forever-lost-folk-rnn-v2-sturm/) by [Bob L.T. Sturm](https://www.kth.se/profile/bobs)

Each week I learn and record one folk tune generated by an Ai system and post a video and description of it. These "machine folk" tunes are problematic for a few reasons. First, their origin is not in /folk/, but instead in a lifeless algorithm operating with statistical procedures extracted from crowd-sourced datasets of music ephemera - the impovershed "dots" of the bones of tunes people play in contexts that are deeply personal and social. Second, these tunes come from nowhere – they are connected to neither places, nor musicians, not even a story. Each is revealed to the world through a computational procedure involving on average one billion operations, and then subsequent efforts on my part to discover them. However, these "machine folk" tunes are _just_ like their "real" folk cousins: authored anonymously by a collective community. They are tunes that I feel /ought/ to be. And many of them are about my dog.

---

<a href="https://ivonatau.com/synthetic-still-life" id="tautkute">![image](https://user-images.githubusercontent.com/1598545/122476928-d49e4000-cf7b-11eb-9817-3f7f468d8a02.png)</a>

[__Synthetic Still Life__](https://ivonatau.com/synthetic-still-life) by [Ivona Tautkute](https://ivonatau.com/ai-art)

The project is a juxtaposition of the artificially generated still life and organic life. The goal of the project is to create new artificial life forms from the stillness of common objects and make them react to sounds of nature as if these synthetic creations were part of natural life in some alternative world and environment.

---

<a href="http://mezs.ai" id="vitols">![image](https://user-images.githubusercontent.com/1598545/122475800-0910fc80-cf7a-11eb-9d94-0304a937f18d.png)</a>

[__Mezs__](http://mezs.ai) by [Rihards Vitols](http://www.vitols.xyz/)

Mezs is a speculative look into plausible new tree species that could cover the earth in the future to maintain natural balance. The new trees are the result of evolution of existing ones and mutations between them. They have qualities from multiple trees from different environments that allow them to be more resilient to future environments, and in some cases, even migrate away from the environment if the conditions for their survival  become too harsh.
The art work engages with my growing interest in the application of AI and forests. Combining data collection of tree species from different environments (deserts, rainforests, tundra, etc.) and Machine Learning image-making techniques styleGans2. The result is a fictional collection of trees that proposes and simulates a future alteration of the planet biodiversity, with results that are often unimaginable, abstract and absurd. I was interested in using  AI not as a solutionist strategy for climate change but to comment on the effects of the Anthropocene on the environment, to speculate about the potential of future imaginations by the collaboration of human and non-human agents, explore the poetics of using AI both visually, and also sonically, create an immersive experience, and disseminate and archive the work.

---

 [Back to main page](http://cmmc-cvpr21.com/)
