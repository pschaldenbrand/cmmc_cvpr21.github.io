# Contributed Artworks

![image](https://user-images.githubusercontent.com/1598545/122474335-ebdb2e80-cf77-11eb-9a64-44bb5ea082bb.png)

[__The Ear__](http://www.estebanagosin.cl/eng/the_ear.html) by [Esteban Y Agosin](http://www.estebanagosin.cl/eng/)

The ear is a listening, surveillance, and Artificial Intelligence project. It is a device that collects human voices, 
transcribe them into text, and with that information create new texts. The ear is a machine that through an Artificial
Intelligence system creates ideas in real time based on what it is listening to. This piece could be defined as an 
ironic idea of the surveillance system. In a way, it is not a perfect and functional machine, it constantly makes 
mistakes, degrading the original information from the source, creating erroneous and potentially false information,
digital garbage that in a way undermines the expected fantasies of technology and surveillance systems. The experience
with the piece show how the human voice is transformed into a digital object and that could be analyzed, recorded, 
transformed, stored, and used, questioning the concept, sense and value of the information, privacy and freedom in
our contemporary society, also questioning the relevance of the information collected in surveillance systems, and
the ethical and political limits in this type of devices.

---

![image](https://user-images.githubusercontent.com/1598545/122474371-f72e5a00-cf77-11eb-9a2e-5a634ef76cc5.png)

[__Models for Environmental Literacy__](https://www.tivonrice.com/models.html) by [Tivon Rice](https://www.tivonrice.com)

Models for Environmental Literacy creatively and critically explores the challenges of describing a landscape, an 
ecosystem, or the specter of environmental collapse through human language. The project further explores how language
and vision are impacted by the mediating agency of new technologies. How do we see, feel, imagine, and talk about the
environment in this post-digital era, when there are indeed non-human/machine agents similarly trained to perceive
“natural” spaces? This project explores these questions, as well as emerging relationships with drone/computer vision
and A.I.

---

[__Permanent Visibility__](https://youtu.be/bazCs9Kyyt4) by [Nica Ross](https://nicaross.com/)

A virtual reality based essay that celebrates the failure of surveillance and nonhuman vision when applied to the human
form. The work is the result of capturing gender non-conforming bodies practicing Brazilian Jiu Jitsu in Carnegie 
Mellon's Panoptic Dome - a sensor-free motion capture studio. As the name implies the technology's intention is to 
fully capture and render the "truth" of a body's performance. Throughout the piece Jeremy Bentham's musings on the
perfection of the Panopticon's form are juxtaposed against the Dome's raw data. We see the noisy shadows of bodies
moving across the Dome's walls, digital skeletons popping in and out of sight as their movements shift outside of a
machine's understanding and we are left with the impression of their contact recorded in millions of point clouds. 
Bentham's words describe an omnipotent yet focused power harnessed by surveillance while queer bodies jump in and 
out of understanding in pursuit of joy rather than legibility.

---

![image](https://user-images.githubusercontent.com/1598545/122475928-3a89c800-cf7a-11eb-9d27-bd0a646b266b.png)

[__Tunes from the Ai Frontiers: Week 36: Evigt Förlorad – Forever Lost (folk-rnn v2 + Sturm)__](https://tunesfromtheaifrontiers.wordpress.com/2021/06/01/week-36-evigt-forlorad-forever-lost-folk-rnn-v2-sturm/) by [Bob L.T. Sturm](https://www.kth.se/profile/bobs)

Each week I learn and record one folk tune generated by an Ai system and post a video and description of it. These "machine folk" tunes are problematic for a few reasons. First, their origin is not in /folk/, but instead in a lifeless algorithm operating with statistical procedures extracted from crowd-sourced datasets of music ephemera - the impovershed "dots" of the bones of tunes people play in contexts that are deeply personal and social. Second, these tunes come from nowhere – they are connected to neither places, nor musicians, not even a story. Each is revealed to the world through a computational procedure involving on average one billion operations, and then subsequent efforts on my part to discover them. However, these "machine folk" tunes are _just_ like their "real" folk cousins: authored anonymously by a collective community. They are tunes that I feel /ought/ to be. And many of them are about my dog.

---
![image](https://user-images.githubusercontent.com/1598545/122475800-0910fc80-cf7a-11eb-9d94-0304a937f18d.png)

[__Mezs__](http://mezs.ai) by [Rihards Vitols](http://www.vitols.xyz/)

Mezs is a speculative look into plausible new tree species that could cover the earth in the future to maintain natural balance. The new trees are the result of evolution of existing ones and mutations between them. They have qualities from multiple trees from different environments that allow them to be more resilient to future environments, and in some cases, even migrate away from the environment if the conditions for their survival  become too harsh.
The art work engages with my growing interest in the application of AI and forests. Combining data collection of tree species from different environments (deserts, rainforests, tundra, etc.) and Machine Learning image-making techniques styleGans2. The result is a fictional collection of trees that proposes and simulates a future alteration of the planet biodiversity, with results that are often unimaginable, abstract and absurd. I was interested in using  AI not as a solutionist strategy for climate change but to comment on the effects of the Anthropocene on the environment, to speculate about the potential of future imaginations by the collaboration of human and non-human agents, explore the poetics of using AI both visually, and also sonically, create an immersive experience, and disseminate and archive the work.
